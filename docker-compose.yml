services:
  raimu:
    restart: unless-stopped 
    container_name: raimu 
    image: ghcr.io/giorgiobrux/raimu:latest
    hostname: raimu 
    environment: 
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
      # OpenAI API key for transcription/TTS (optional)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # Hugging Face token for model access
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      # Log level: trace, debug, info, warn, error (default: info)
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - TRANSFORMERS_VERBOSITY=info
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      - HF_HOME=/root/.cache/huggingface
      - HUGGINGFACE_HUB_CACHE=/root/.cache/huggingface
      - TORCH_DEVICE=cuda
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    labels:
      com.github.saltbox.saltbox_managed: true 
      # Frontend
      traefik.enable: true 
      traefik.http.routers.raimu-http.entrypoints: web 
      traefik.http.routers.raimu-http.middlewares: globalHeaders@file,redirect-to-https@docker,robotHeaders@file,cloudflarewarp@docker 
      traefik.http.routers.raimu-http.rule: Host(`raimu.${DOMAIN}`) 
      traefik.http.routers.raimu-http.service: raimu 
      traefik.http.routers.raimu.entrypoints: websecure 
      traefik.http.routers.raimu.middlewares: globalHeaders@file,secureHeaders@file,robotHeaders@file,cloudflarewarp@docker 
      traefik.http.routers.raimu.rule: Host(`raimu.${DOMAIN}`) 
      traefik.http.routers.raimu.service: raimu 
      traefik.http.routers.raimu.tls.certresolver: cfdns 
      traefik.http.routers.raimu.tls.options: securetls@file 
      traefik.http.services.raimu.loadbalancer.server.port: 4000
    ports:
      - "0.0.0.0:4000:4000"  # Main application port
      - "19302:19302/udp"  # STUN uses UDP
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - /kagi/model_cache:/root/.cache/huggingface  # Single mount point for all caches